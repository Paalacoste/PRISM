# PRISM ‚Äî Predictive Representation for Introspective Spatial Metacognition

> Premier test computationnel de la th√®se neuroscientifique de la m√©ta-carte hippocampique :
> la successor representation comme substrat unifi√© pour la cognition et la m√©tacognition,
> √©valu√© avec les outils de la psychophysique.

---

## 1. Revue de litt√©rature

### 1.1 Successor representations ‚Äî fondements

Le formalisme des successor representations a √©t√© introduit par **Dayan (1993)** comme compromis entre apprentissage model-free (efficace mais rigide) et model-based (flexible mais co√ªteux). L'id√©e centrale est la d√©composition de la fonction de valeur V(s) = M ¬∑ R, o√π M encode les transitions pr√©dites et R les r√©compenses, permettant une adaptation rapide quand l'un change ind√©pendamment de l'autre.

**Stachenfeld, Botvinick & Gershman (2017, Nature Neuroscience)** ont reformul√© l'hippocampe comme "carte pr√©dictive" : les cellules de lieu CA1 n'encodent pas la position g√©od√©sique mais la probabilit√© de transition vers les positions futures. Les grid cells du cortex entorhinal √©mergent comme eigenvectors de la matrice SR ‚Äî une compression spectrale multi-√©chelle. Cette th√©orie pr√©dit et explique l'expansion asym√©trique des champs de lieu, le clustering, la sensibilit√© √† la r√©compense et les cellules de temps.

**Gershman (2018, J. Neuroscience)** a fourni une synth√®se de la logique computationnelle et des substrats neuronaux de la SR, √©tablissant qu'elle ne fonctionne pas en isolation mais interagit avec des computations model-based et model-free.

**Momennejad, Russek et al. (2017, Nature Human Behaviour)** ont fourni les premi√®res preuves comportementales chez l'humain : les sujets montrent une sensibilit√© aux changements de r√©compense (comme pr√©dit par la SR) mais une insensibilit√© aux changements de transition (signature unique de la SR vs. model-based). Leurs donn√©es montrent un mod√®le hybride SR‚ÄìMB.

**Russek, Momennejad et al. (2017, PLoS Comp Bio)** ont formalis√© comment les computations model-based peuvent √™tre construites sur un socle de TD learning via la SR, avec des extensions Dyna-SR qui utilisent le replay hippocampique pour mettre √† jour la matrice M offline.

### 1.2 Au-del√† de l'espace physique ‚Äî espaces cognitifs

**Bellmund et al. (2018, Science)** ont montr√© que les codes spatiaux hippocampiques op√®rent sur des "espaces cognitifs" abstraits ‚Äî des espaces dont les dimensions peuvent √™tre le poids, la hi√©rarchie sociale, ou les features s√©mantiques.

**Theves, Fernandez & Doeller (2020, J. Neuroscience)** ont prouv√© que l'hippocampe cartographie l'espace conceptuel plut√¥t que l'espace des features bruts : le signal de distance hippocampique refl√®te s√©lectivement les dimensions conceptuellement pertinentes.

**Stoewer et al. (2023, Scientific Reports)** ont d√©montr√© que des r√©seaux de neurones artificiels apprenant des SR sur des espaces s√©mantiques (32 esp√®ces animales) construisent avec succ√®s des cartes cognitives capturant les similarit√©s entre concepts.

**Ekman et al. (2023, eLife)** ont montr√© que le cortex visuel primaire V1 et l'hippocampe repr√©sentent une carte pr√©dictive apparent√©e √† la SR ‚Äî les repr√©sentations pr√©dictives impr√®gnent le traitement perceptif lui-m√™me.

### 1.3 Hippocampe et m√©tacognition ‚Äî la th√®se de la m√©ta-carte

Le lien le plus direct avec PRISM provient de la th√®se de la **m√©ta-carte hippocampique** propos√©e par **Ambrogioni & √ìlafsd√≥ttir (2023, Trends in Cognitive Sciences)** ‚Äî ¬´ Rethinking the hippocampal cognitive map as a meta-learning computational module ¬ª : l'hippocampe n'encode pas seulement des cartes d'environnements familiers, mais aussi des √©tats informationnels et des sources d'information. Les cartes cognitives feraient partie d'une m√©ta-repr√©sentation plus large qui soutient l'exploration et fournit un fondement pour l'apprentissage en contexte d'incertitude.

**Allen et al. (2017, NeuroImage)** ont montr√© par IRM quantitative que la capacit√© m√©tacognitive corr√®le avec la microstructure de l'hippocampe et du cortex pr√©frontal ant√©rieur ‚Äî confirmation neuroanatomique que m√©tacognition et cognition spatiale partagent des substrats.

**Qiu et al. (2024, Communications Biology)** ont confirm√© en IRMf que l'hippocampe, le cortex entorhinal et le cortex orbitofrontal collaborent pour apprendre la structure d'espaces abstraits multidimensionnels.

### 1.4 SR et incertitude ‚Äî travaux existants

**Janz et al. (2019, NeurIPS) ‚Äî Successor Uncertainties.** Combinaison de successor features avec la r√©gression lin√©aire bay√©sienne pour propager l'incertitude √† travers la structure temporelle du MDP. L'incertitude guide l'exploration via posterior sampling (PSRL). Surpasse la performance humaine sur 38/49 jeux Atari. C'est le travail le plus proche de PRISM sur l'axe SR + incertitude.

**Machado, Bellemare & Bowling (2020, AAAI) ‚Äî Count-based exploration with SR.** Utilisent la norme de la SR comme proxy pour les visites d'√©tats, d√©rivant des bonus d'exploration count-based √† partir de la structure SR.

**Flennerhag et al. (2020, DeepMind) ‚Äî Temporal Difference Uncertainties as Signal for Exploration.** Proposent d'utiliser les incertitudes des diff√©rences temporelles comme signal d'exploration, conceptuellement proche du monitoring d'erreurs TD de PRISM.

### 1.5 M√©tacognition en IA ‚Äî frameworks existants

**Valiente & Pilly (2024, arXiv; 2025, Neural Networks) ‚Äî MUSE Framework.** Int√®gre self-assessment et self-regulation dans des agents autonomes. Deux impl√©mentations : world model et LLM. Test√© dans Meta-World et ALFWorld. Le framework le plus complet pour la m√©tacognition computationnelle, mais n'utilise pas la SR comme substrat.

**Kawato et al. (2021, Biological Cybernetics) ‚Äî From Internal Models toward Metacognitive AI.** Propose un mod√®le computationnel de la m√©tacognition bas√© sur des paires de mod√®les g√©n√©ratifs-inverses avec un "responsibility signal" qui gate la s√©lection et l'apprentissage. Le signal de responsabilit√© est conceptuellement proche du monitoring d'erreurs de pr√©diction de PRISM.

**Meta-Cognitive RL (VPES).** Framework r√©cent o√π un m√©ta-contr√¥leur monitore la stabilit√© des erreurs de pr√©diction de valeur (Value Prediction Error Stability) pour r√©guler le taux d'apprentissage. Architecturalement proche de la m√©ta-SR de PRISM.

**Steyvers & Peters (2025, Perspectives on Psychological Science).** Survey sur la m√©tacognition et la communication d'incertitude chez les humains et les LLMs, identifiant la calibration de confiance comme m√©trique cl√©.

### 1.6 Cadre englobant ‚Äî l'Espace de Travail Neuronal Global (GNW)

La Global Neuronal Workspace de **Dehaene & Changeux (1998, 2011)** est la th√©orie dominante de l'acc√®s conscient : des neurones pyramidaux √† axones longs (pr√©frontaux, pari√©taux) forment un workspace global o√π l'information subit une "ignition" non-lin√©aire, tout-ou-rien, la rendant accessible √† l'ensemble des processeurs sp√©cialis√©s. La GNW est une th√©orie du **broadcast** ‚Äî ce qui entre dans le workspace devient conscient.

Deux r√©sultats rendent la GNW pertinente pour PRISM :

**L'hippocampe fait partie du core du workspace.** Deco, Vidaurre & Kringelbach (2021, *Nature Human Behaviour*) ont quantifi√© empiriquement le "functional rich club" constituant le workspace global √† travers sept t√¢ches + repos. L'hippocampe figure dans le noyau central, aux c√¥t√©s du precuneus, du cingulaire post√©rieur et du noyau accumbens. La carte pr√©dictive SR n'est donc pas un processus p√©riph√©rique isol√© ‚Äî elle alimente directement le hub de diffusion global.

**Le "predictive global workspace".** Whyte & Smith (2020, *Progress in Neurobiology*) int√®grent la GNW avec l'active inference de Friston, montrant que le workspace peut √™tre compris comme le lieu o√π les erreurs de pr√©diction sont s√©lectionn√©es et diffus√©es. PRISM op√®re exactement dans cet espace d'erreurs de pr√©diction ‚Äî en amont du broadcast.

La GNW et PRISM op√®rent √† des √©chelles diff√©rentes et ne sont pas en comp√©tition. La GNW d√©crit comment l'information m√©tacognitive devient **globalement accessible**. PRISM d√©crit **d'o√π elle vient** ‚Äî le monitoring de la structure pr√©dictive SR au sein du module hippocampique. Le positionnement pr√©cis est d√©velopp√© en ¬ß3.4.

---

## 2. Revue des r√©sultats et impl√©mentations existants

### 2.1 Ce qui a √©t√© d√©montr√© exp√©rimentalement

| R√©sultat | Auteurs | Statut |
|----------|---------|--------|
| SR tabulaire converge dans FourRooms | Juliani (2019, tutorial) | ‚úÖ Reproduit, code dispo |
| Eigenvectors de M ‚Üí patterns grid-like | Stachenfeld et al. (2017); Chelu (repo) | ‚úÖ Reproduit, code dispo |
| Transfert SR quand R change (M r√©utilis√©) | Juliani (2019); Barreto et al. (2017) | ‚úÖ Reproduit, code dispo |
| Humains utilisent SR + arbitrage SR/MB | Momennejad et al. (2017) | ‚úÖ Donn√©es + mod√®le dispo |
| SR + incertitude bay√©sienne ‚Üí exploration | Janz et al. (2019) | ‚úÖ R√©sultats Atari-scale |
| Count-based exploration via norme SR | Machado et al. (2020) | ‚úÖ R√©sultats AAAI |
| SF apprises depuis pixels dans MiniGrid | Chua et al. (2024) | ‚úÖ Code dispo |
| M√©tacognition comme self-assessment RL | Valiente & Pilly (2024) | ‚úÖ Meta-World + ALFWorld |

### 2.2 Ce qui n'a PAS √©t√© fait

| Gap | Pourquoi c'est un gap | PRISM le comble ? |
|-----|----------------------|-------------------|
| Carte d'incertitude iso-structurale √† la SR | Successor Uncertainties propage l'incertitude mais ne construit pas une carte spatiale parall√®le | ‚úÖ Contribution principale |
| Calibration psychophysique d'un agent SR | Personne n'a mesur√© l'ECE d'un agent SR ni produit de reliability diagram | ‚úÖ Protocole Exp A |
| Signal "je ne sais pas" calibr√© et continu | MUSE fait du self-assessment mais sans m√©triques de calibration formelles | ‚úÖ Protocole Exp A |
| Test computationnel de la m√©ta-carte hippocampique | La th√®se TiCS 2023 est th√©orique, jamais impl√©ment√©e | ‚úÖ Cadrage du projet |
| Exploration dirig√©e par incertitude SR structurale | Machado (2020) utilise la norme SR ; Janz (2019) utilise le posterior ‚Äî ni l'un ni l'autre n'utilise une carte U(s) parall√®le | ‚úÖ Protocole Exp B |
| Comparaison incertitude SR structurale vs. bay√©sienne vs. count-based | Chaque approche a √©t√© √©valu√©e isol√©ment | ‚úÖ Protocole Exp B |

### 2.3 Assets r√©utilisables

| Asset | Source | Usage dans PRISM |
|-------|--------|-----------------|
| **MiniGrid** FourRooms | Farama Foundation (NeurIPS 2023) | Environnement de base ‚Äî pas de gridworld custom |
| SR tabulaire + visualisations | Juliani (2019) | Point de d√©part pour l'agent SR |
| D√©composition spectrale SR | Chelu (github/temporal_abstraction) | Visualisation eigenvectors, eigenvalues |
| Mod√®le SR/MB hybride | Russek et al. (2017, github) | R√©f√©rence pour l'arbitrage |
| Simple Successor Features | Chua et al. (2024, github) | Deep SF si extension future |
| Baselines RL | Stable-Baselines3 | Q-learning, DQN baselines |

---

## 3. Positionnement de PRISM

### 3.1 Carte de positionnement

```
    Axe Y : Rigueur m√©tacognitive (m√©triques psychophysiques)
    √¢‚Äì¬≤
    ‚îÇ
    ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   ‚îÇ  PRISM  ‚îÇ  SR comme substrat naturel pour la m√©tacognition
    ‚îÇ   ‚îÇ         ‚îÇ  Calibration ECE, reliability diagrams
    ‚îÇ   ‚îÇ         ‚îÇ  Carte d'incertitude iso-structurale
    ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ        ‚ñ≤
    ‚îÇ        ‚îÇ apporte les m√©triques        apporte le substrat SR
    ‚îÇ        ‚îÇ m√©tacognitives                    ‚îÇ
    ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   ‚îÇ  MUSE   ‚îÇ                    ‚îÇ Succ. Uncertain. ‚îÇ
    ‚îÇ   ‚îÇ         ‚îÇ                    ‚îÇ                  ‚îÇ
    ‚îÇ   ‚îÇ Self-assessment              ‚îÇ SR + bay√©sien    ‚îÇ
    ‚îÇ   ‚îÇ Self-regulation              ‚îÇ pour exploration ‚îÇ
    ‚îÇ   ‚îÇ (world model / LLM)          ‚îÇ (posterior samp.)‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ Axe X : Ancrage SR
    ‚îÇ
    ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   ‚îÇ VPES /    ‚îÇ          ‚îÇ Machado 2020 ‚îÇ
    ‚îÇ   ‚îÇ Meta-Cog  ‚îÇ          ‚îÇ Count + SR   ‚îÇ
    ‚îÇ   ‚îÇ RL        ‚îÇ          ‚îÇ              ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 3.2 Contribution unique

**PRISM est le premier projet √† :**

1. Construire une **carte d'incertitude iso-structurale** √† la SR ‚Äî m√™me formalisme pour cognition de premier ordre (M : "o√π vais-je ?") et m√©tacognition (U : "est-ce que je sais o√π je vais ?")

2. Mesurer la **calibration m√©tacognitive** d'un agent SR avec les outils de la psychophysique (ECE, reliability diagrams, Metacognitive Index) ‚Äî traiter un agent RL comme un sujet de psychologie cognitive

3. **Tester computationnellement** la th√®se de la m√©ta-carte hippocampique (TiCS, 2023), en montrant que la structure pr√©dictive de la SR suffit √† faire √©merger des comportements m√©tacognitifs sans module m√©tacognitif externe

### 3.3 Ce que PRISM ne pr√©tend PAS faire

- Surpasser Successor Uncertainties en performance d'exploration (ils op√®rent √† l'√©chelle Atari, PRISM est tabulaire)
- Remplacer MUSE comme framework g√©n√©ral de m√©tacognition (PRISM est sp√©cifique au substrat SR)
- Prouver que le cerveau utilise la m√©ta-SR (PRISM est un test computationnel, pas une validation neurobiologique)
- Mod√©liser la conscience ou l'acc√®s conscient (c'est le territoire de la GNW, voir ci-dessous)

### 3.4 Positionnement par rapport √† l'Espace de Travail Neuronal Global (GNW)

La Global Neuronal Workspace de Dehaene-Changeux (1998, 2011) est la th√©orie dominante de l'acc√®s conscient. PRISM et la GNW ne sont pas en comp√©tition ‚Äî ils op√®rent √† des √©chelles diff√©rentes.

**PRISM mod√©lise un processeur sp√©cialis√© qui alimente le workspace.** L'hippocampe fait partie du noyau central du workspace global (Deco et al., 2021). La carte pr√©dictive SR et la m√©ta-carte U(s) produisent des signaux ‚Äî erreurs de pr√©diction, incertitude ‚Äî qui peuvent √™tre diffus√©s vers le workspace. PRISM mod√©lise la **computation locale** qui g√©n√®re ces signaux. La GNW mod√©lise comment ils deviennent **globalement accessibles**.

| | GNW (Dehaene-Changeux) | PRISM |
|---|---|---|
| √âchelle | Cerveau entier | Module hippocampique |
| M√©canisme cl√© | Ignition + broadcast | Erreur de pr√©diction SR + m√©ta-carte |
| Question centrale | Comment l'information devient consciente ? | D'o√π vient le signal d'incertitude ? |
| M√©tacognition | Requiert l'acc√®s au workspace | √âmerge de la structure pr√©dictive locale |
| Dynamique | Tout-ou-rien (seuil d'ignition) | Continue (U(s)) + seuil (d√©tection changement) |

**Point de contact cl√© ‚Äî le seuil de d√©tection.** La **d√©tection de changement** de PRISM ‚Äî quand `change_score > Œ∏_change` ‚Äî a la structure d'un seuil d'ignition GNW : une transition discr√®te qui r√©oriente la strat√©gie de l'agent. Le `Œ∏_change` pourrait √™tre l'analogue fonctionnel du seuil d'ignition, local √† l'hippocampe. Tester si ce seuil exhibe les propri√©t√©s de l'ignition (non-lin√©arit√©, hyst√©r√©sis) est une extension future hors-scope de la v1.

---

## 4. Th√®se resserr√©e

### Hypoth√®se principale

> La successor representation fournit un substrat **naturel** pour la m√©tacognition :
> une carte d'incertitude construite √† partir des erreurs de pr√©diction SR
> (iso-structurale √† la carte pr√©dictive elle-m√™me) produit des signaux de confiance
> **mieux calibr√©s** que les approches d'incertitude non-structur√©es,
> et cela soutient la th√®se neuroscientifique de la m√©ta-carte hippocampique.

### Pr√©dictions testables

**P1 ‚Äî Calibration.** Le signal de confiance C(s) d√©riv√© de la m√©ta-SR est calibr√© : les d√©cisions √† haute confiance sont correctes plus souvent que les d√©cisions √† basse confiance. ECE < 0.15.

**P2 ‚Äî Iso-structuralit√©.** La carte d'incertitude U(s) a une structure spatiale coh√©rente avec la carte pr√©dictive M : les fronti√®res d'incertitude correspondent aux fronti√®res topologiques du monde (portes, zones inexplor√©es, zones r√©cemment modifi√©es).

**P3 ‚Äî Avantage de la structure.** L'exploration guid√©e par U(s) (structur√©e spatialement) est plus efficace que l'exploration guid√©e par des signaux d'incertitude non-structur√©s (count-based, Œµ-greedy, variance globale).

---

## 5. Architecture

### 5.1 Vue d'ensemble

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              MONDE ‚Äî MiniGrid FourRooms                  ‚îÇ
‚îÇ  (Farama Foundation, asset existant)                     ‚îÇ
‚îÇ  + DynamicsWrapper (√† coder)                             ‚îÇ
‚îÇ    - D√©placement de r√©compense                           ‚îÇ
‚îÇ    - Blocage/ouverture de porte                          ‚îÇ
‚îÇ    - Schedule de perturbations                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ (s, a, r, s')
                         √¢‚Äì¬º
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  AGENT PRISM                              ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ  Couche SR ‚Äî premier ordre                     ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  (adapt√© de Juliani 2019 / Chua et al. 2024)   ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  M(s,s') : transitions pr√©dites (TD learning)  ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  R(s) : r√©compenses apprises                   ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  V(s) = M ¬∑ R                                  ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                        ‚îÇ Œ¥(s) = || TD error on M ||       ‚îÇ
‚îÇ                        ‚ñº                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ  Couche M√©ta-SR ‚Äî CONTRIBUTION PRISM ‚òÖ         ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  U(s) : carte d'incertitude (buffer Œ¥ glissant)‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  C(s) : signal de confiance calibr√©            ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  D√©tection de changement structurel            ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  Iso-structurale √† M par construction          ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                        ‚îÇ C(s), U(s)                       ‚îÇ
‚îÇ                        ‚ñº                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ  Contr√¥leur                                    ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  Œµ_adaptive(s) = f(U(s))                       ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  V_explore(s) = V(s) + Œª ¬∑ U(s)               ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  Signal "je ne sais pas" quand C(s) < Œ∏        ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 5.2 Le monde ‚Äî MiniGrid + DynamicsWrapper

**Base :** `MiniGrid-FourRooms-v0` (Farama Foundation). Grille modulaire avec 4 pi√®ces connect√©es par des portes. Interface Gymnasium standard.

**Extension custom ‚Äî `DynamicsWrapper` :** Wrapper Gymnasium qui ajoute les perturbations dynamiques au-dessus de n'importe quel env MiniGrid. C'est le seul composant "monde" √† coder.

```python
class DynamicsWrapper(gymnasium.Wrapper):
    """Ajoute des perturbations contr√¥l√©es √† un env MiniGrid."""
    
    def apply_perturbation(self, ptype: str, **kwargs):
        """Types : 'reward_shift', 'door_block', 'door_open', 'combined'"""
    
    def set_schedule(self, schedule: PerturbationSchedule):
        """Schedule configurable : p√©riodique, al√©atoire, triggered."""
    
    def get_state_index(self, pos: tuple) -> int:
        """Mapping position ‚Üí index d'√©tat pour la matrice SR."""
    
    def get_true_transition_matrix(self) -> np.ndarray:
        """Ground truth pour validation."""
```

### 5.3 La couche SR ‚Äî premier ordre

Adapt√© depuis les impl√©mentations existantes (Juliani 2019). Pas de contribution ici ‚Äî c'est un composant standard.

**Matrice SR ‚Äî M ‚àà ‚Ñù^(N√óN) :**

```
M(s, s') = E[ Œ£_t Œ≥^t ùüô(s_t = s') | s_0 = s, œÄ ]
```

**Mise √† jour TD(0) :**

```
Œ¥_M(s) = e(s') + Œ≥ ¬∑ M(s',:) - M(s,:)
M(s,:) ‚Üê M(s,:) + Œ±_M ¬∑ Œ¥_M(s)
```

**Fonction de valeur :** V(s) = M(s,:) ¬∑ R

**Param√®tres :**

| Param√®tre | Symbole | D√©faut | R√¥le |
|-----------|---------|--------|------|
| Discount factor | Œ≥ | 0.95 | Horizon temporel SR |
| Learning rate SR | Œ±_M | 0.1 | Vitesse d'apprentissage M |
| Learning rate R | Œ±_R | 0.3 | Vitesse d'apprentissage R |
| Exploration base | Œµ | 0.1 | Taux exploration par d√©faut |

### 5.4 La couche M√©ta-SR ‚Äî CONTRIBUTION PRINCIPALE ‚òÖ

L'id√©e fondatrice : la carte d'incertitude a **exactement la m√™me structure** que la carte pr√©dictive. M√™me indexation par √©tat, m√™me granularit√© spatiale. Ce n'est pas un module externe qui observe la SR ‚Äî c'est un **reflet** de la SR.

**Erreur de pr√©diction SR scalaire par visite :**

```
Œ¥(s) = || e(s') + Œ≥ ¬∑ M(s',:) - M(s,:) ||‚ÇÇ
```

**Justification de la compression scalaire.** Le vecteur d'erreur TD complet Œ¥_vec(s) ‚àà ‚Ñù^N contient de l'information directionnelle (vers quels √©tats la pr√©diction est mauvaise), mais la norme L2 suffit pour notre objectif principal : mesurer si l'agent sait que sa carte est fiable *en un √©tat donn√©*. La version scalaire permet de maintenir l'iso-structuralit√© (un scalaire par √©tat, comme M a une ligne par √©tat) tout en restant computationnellement l√©g√®re. Une extension vectorielle U(s, s') ‚Äî qui conserverait la structure compl√®te ‚Äî est envisageable mais sort du scope de la v1. La compression scalaire est test√©e empiriquement : si le MI (corr√©lation entre U(s) et l'erreur r√©elle) est √©lev√©, la compression ne perd pas d'information critique pour la calibration.

**Buffer d'erreurs glissant ‚Äî ŒîM_history(s) :**

Pour chaque √©tat s, buffer circulaire de taille K (d√©faut : 20) des Œ¥ observ√©s lors des visites √† s.

**Carte d'incertitude ‚Äî U(s) ‚àà [0, 1] :**

```
U(s) = {
    mean(ŒîM_history(s))           si visits(s) ‚â• K
    U_max                          si visits(s) = 0
    U_prior ¬∑ decay^(visits(s))    si 0 < visits(s) < K
}
```

**Signal de confiance ‚Äî C(s) ‚àà [0, 1] :**

```
C(s) = 1 - sigmoid(Œ≤ ¬∑ (U(s) - Œ∏_C))
```

**D√©tection de changement :**

```
change_score = mean(U(s) for s in recently_visited)
change_detected = change_score > Œ∏_change
```

**Exploration adaptative :**

```
Œµ_adaptive(s) = Œµ_min + (Œµ_max - Œµ_min) ¬∑ U(s) / U_max
V_explore(s) = V(s) + Œª ¬∑ U(s)
```

**Param√®tres m√©ta-SR ‚Äî valeurs par d√©faut et justification :**

| Param√®tre | Symbole | D√©faut | Justification |
|-----------|---------|--------|---------------|
| Taille buffer | K | 20 | ~5 travers√©es compl√®tes d'une pi√®ce de FourRooms. Assez pour estimer la variance, assez petit pour d√©tecter les changements. |
| Prior d'incertitude | U_prior | 0.8 | Conservateur : un √©tat non visit√© est suppos√© hautement incertain. |
| Decay du prior | decay | 0.85 | Chaque visite r√©duit l'incertitude prior de 15%. Apr√®s 10 visites, U ‚âà 0.16 (basse). |
| Pente sigmo√Øde confiance | Œ≤ | 10 | Transition nette autour de Œ∏_C. Valid√© par sweep [5, 10, 20] en Exp A. |
| Seuil de confiance | Œ∏_C | 0.3 | Centre de la sigmo√Øde C(s). U < 0.3 ‚Üí haute confiance, U > 0.3 ‚Üí basse. |
| Seuil de changement | Œ∏_change | 0.5 | D√©tection de changement. Valid√© par analyse ROC en Exp C. |
| Bonus exploration | Œª | 0.5 | Poids relatif exploration/exploitation dans V_explore. |
| Epsilon min | Œµ_min | 0.01 | Plancher d'exploration m√™me en haute confiance. |
| Epsilon max | Œµ_max | 0.5 | Plafond d'exploration en haute incertitude. |

**Analyse de sensibilit√© (Exp A, phase pr√©liminaire) :** Avant les comparaisons formelles, un sweep factoriel sur {U_prior, decay, Œ≤, Œ∏_C} sera r√©alis√© (4 param√®tres √ó 3 valeurs = 81 configs, 10 runs chacune). Le crit√®re de s√©lection est l'ECE minimal sur la phase d'apprentissage stable. Les param√®tres s√©lectionn√©s sont ensuite fix√©s pour toutes les exp√©riences. Ce sweep est report√© en annexe pour √©viter le p-hacking.

**Propri√©t√© cl√© ‚Äî iso-structuralit√© :** U est index√© par les m√™mes √©tats que M. On peut superposer visuellement la carte pr√©dictive et la carte d'incertitude. Les fronti√®res de haute incertitude devraient correspondre aux fronti√®res topologiques (portes, zones inexplor√©es, zones perturb√©es). C'est cette propri√©t√© qui est test√©e dans l'Exp A.

---

## 6. Protocole exp√©rimental

Trois exp√©riences profondes au lieu de cinq superficielles. Chacune teste une pr√©diction sp√©cifique.

### 6.1 Exp√©rience A ‚Äî Calibration m√©tacognitive (teste P1 + P2)

**Question :** Le signal de confiance C(s) est-il calibr√© ? La carte U(s) est-elle iso-structurale √† M ?

**Protocole :**

1. **Phase apprentissage** (300 √©pisodes) : monde stable, 4 pi√®ces, goal fixe. L'agent apprend M et construit U.
2. **Phase exploration** (100 √©pisodes) : on ouvre une nouvelle zone (5e pi√®ce) jamais vue.
3. **Phase perturbation** (100 √©pisodes) : on d√©place le goal dans la nouvelle zone.
4. √Ä chaque step, l'agent √©met C(s) ‚Äî sa confiance.

**M√©triques :**

**Calibration ‚Äî Expected Calibration Error (ECE) :**

```
ECE = Œ£_b (|B_b| / N) ¬∑ |accuracy(B_b) - confidence(B_b)|
```

On d√©coupe les pr√©dictions en 10 bins de confiance. Pour chaque bin, on compare la confiance moyenne C(s) et le taux de ¬´ pr√©dictions fiables ¬ª. **D√©finition op√©rationnelle de l'accuracy :** une pr√©diction est consid√©r√©e comme fiable quand l'erreur r√©elle de la SR est faible, i.e. ||M(s,:) - M*(s,:)||‚ÇÇ < œÑ_accuracy, o√π M* est la vraie matrice de transition. Ce choix est coh√©rent avec ce que C(s) est cens√© pr√©dire : non pas la stochasticit√© des transitions (nulle dans MiniGrid ‚Äî l'environnement est d√©terministe), mais la *fiabilit√© de la carte M elle-m√™me*. Le seuil œÑ_accuracy est fix√© au 50e percentile de ||M - M*|| sur l'ensemble des √©tats, de sorte que la baseline d'accuracy est ~50%. Cela garantit une dynamique informative dans le reliability diagram.

**Iso-structuralit√© ‚Äî Corr√©lation spatiale :**

```
œÅ = corr(U(s), d(s, frontier))
```

La carte d'incertitude devrait corr√©ler avec la distance aux fronti√®res topologiques (portes, zones inexplor√©es). On mesure aussi la corr√©lation entre U(s) et l'erreur r√©elle de la SR (ground truth) :

```
MI = corr(U(s), ||M(s,:) - M*(s,:)||)  o√π M* est la vraie matrice de transition
```

MI = Metacognitive Index. C'est la m√©trique reine : l'agent sait-il ce qu'il ne sait pas ?

**Reliability diagram :** graphique confiance d√©clar√©e vs. accuracy observ√©e, par bin. Une courbe sur la diagonale = calibration parfaite.

**Conditions :**

| Condition | Signal de confiance | Description |
|-----------|--------------------|-------------|
| **PRISM** | C(s) = f(U(s)), U structur√© spatialement | Notre approche |
| SR-Global | Confiance = f(erreur TD moyenne globale) | Incertitude non-structur√©e |
| SR-Count | Confiance = f(1/‚àövisits(s)) | Count-based (Machado-like) |
| SR-Bayesian | Posterior sur V via r√©gression lin√©aire | Successor Uncertainties-like |
| Random-Conf | Confiance al√©atoire | Baseline plancher |

**Crit√®res de succ√®s :**
- ECE(PRISM) < 0.15
- MI(PRISM) > 0.5 (corr√©lation mod√©r√©e √† forte)
- ECE(PRISM) < ECE(SR-Global) et ECE(SR-Count) ‚Äî la structure spatiale aide la calibration
- Le reliability diagram montre une corr√©lation positive claire

**Visualisations :**
- Heatmap de M pour quelques √©tats sources (validation SR standard)
- Heatmap de U superpos√©e au monde ‚Äî la carte d'incertitude
- Reliability diagram par condition
- √âvolution temporelle de U apr√®s perturbation (animation ou s√©quence)
- Top-6 eigenvectors de M (validation spectrale standard)

### 6.2 Exp√©rience B ‚Äî Exploration dirig√©e par incertitude structurelle (teste P3)

**Question :** L'exploration guid√©e par U(s) (structur√© spatialement) est-elle plus efficace que les alternatives ?

**Protocole :**

1. Grand monde MiniGrid (19√ó19) avec 4+ pi√®ces
2. 4 goals cach√©s, un par pi√®ce (l'agent ne les conna√Æt pas au d√©part)
3. L'agent doit trouver les 4 goals le plus vite possible
4. Comparer l'efficacit√© d'exploration selon la strat√©gie

**Conditions :**

| Condition | Strat√©gie d'exploration | Signal directeur |
|-----------|------------------------|------------------|
| **PRISM** | V_explore = V + Œª¬∑U(s) | Carte U structur√©e |
| SR-Oracle | V + Œª¬∑||M(s,:) - M*(s,:)|| | Erreur r√©elle (plafond th√©orique) |
| SR-Œµ-greedy | Œµ fixe = 0.1 | Aucun |
| SR-Œµ-decay | Œµ d√©croissant | Aucun |
| SR-Count-Bonus | V + Œª/‚àövisits(s) | Comptage (Machado-like) |
| SR-Norm-Bonus | V + Œª/||M(s,:)|| | Norme SR (Machado 2020) |
| SR-Posterior | Posterior sampling sur V | Bay√©sien (Janz-like) |
| Random | Uniform√©ment al√©atoire | Baseline plancher |

**SR-Oracle** conna√Æt les vraies erreurs de M et les utilise comme bonus. C'est un plafond de performance ‚Äî aucun agent r√©aliste ne peut faire mieux. Le ratio (performance PRISM - Random) / (performance Oracle - Random) quantifie quelle fraction du gain th√©orique PRISM capture (¬´ efficiency ratio ¬ª).

**M√©triques :**
- Steps pour trouver les 4 goals (moyenne sur 100 runs)
- Couverture (% d'√©tats visit√©s) vs. steps
- Redondance : ratio revisites / nouvelles visites
- Corr√©lation entre l'ordre de visite des r√©gions et leur U(s)
- Efficiency ratio : (steps_Random - steps_PRISM) / (steps_Random - steps_Oracle) ‚Äî fraction du gain th√©orique captur√©e

**Crit√®re de succ√®s :** PRISM trouve les 4 goals en significativement moins de steps que SR-Œµ-greedy et SR-Count-Bonus.

**Test diff√©rentiel cl√© :** PRISM vs. SR-Count-Bonus isole l'apport de la structure. Les deux donnent un bonus d'exploration, mais PRISM utilise l'erreur de pr√©diction SR (structur√©e) tandis que Count-Bonus utilise les visites (non-structur√©e). Si PRISM gagne, c'est que la structure pr√©dictive de la SR apporte quelque chose au-del√† du simple comptage.

### 6.3 Exp√©rience C ‚Äî Adaptation au changement (teste P1 + P2 en dynamique)

**Question :** L'agent d√©tecte-t-il les changements et adapte-t-il son comportement, tout en maintenant une confiance calibr√©e ?

**Protocole :**

1. **Phase stable** (200 √©pisodes) : monde fixe, l'agent ma√Ætrise l'environnement.
2. **Perturbation de type R** (100 √©pisodes) : goal d√©plac√©. M reste valide, R change.
3. **Re-stabilisation** (100 √©pisodes) : l'agent se r√©adapte.
4. **Perturbation de type M** (100 √©pisodes) : porte bloqu√©e. M devient invalide, R ne change pas.
5. **Re-stabilisation finale** (100 √©pisodes).

Ce design teste la pr√©diction SR classique (Momennejad 2017) : l'adaptation au changement de R devrait √™tre rapide (seul R est mis √† jour), l'adaptation au changement de M devrait √™tre lente (toute la matrice doit √™tre r√©apprise).

**Pr√©diction quantitative de l'asym√©trie R/M.** Pour un changement de R (goal d√©plac√©), l'adaptation n√©cessite ~O(1/Œ±_R) √©pisodes pour converger ‚Äî avec Œ±_R = 0.3, cela donne ~3-5 √©pisodes. Pour un changement de M (porte bloqu√©e), les lignes de M correspondant aux N_affected √©tats dont les transitions changent doivent √™tre r√©apprises ‚Äî cela prend ~O(N_affected / Œ±_M) √©pisodes. Dans FourRooms, bloquer une porte affecte ~8-12 √©tats adjacents √† la porte ; avec Œ±_M = 0.1, cela donne ~80-120 √©pisodes. Le ratio pr√©dit est donc latence_M / latence_R ‚âà 15-40√ó. Si le ratio observ√© tombe significativement en dehors de cette plage, cela pointerait vers un m√©canisme non-SR (trop bas ‚Üí model-based ; trop haut ‚Üí pas de r√©apprentissage M).

**M√©triques :**
- **Latence de d√©tection** : √©pisodes avant `change_detected = true`
- **Latence d'adaptation** : √©pisodes pour retrouver 80% de la performance pr√©-perturbation
- **Calibration dynamique** : ECE mesur√© dans une fen√™tre glissante de 20 √©pisodes ‚Äî la calibration se maintient-elle pendant et apr√®s les transitions ?
- **Asym√©trie R vs. M** : ratio latence_M / latence_R ‚Äî devrait √™tre >> 1 si la SR est bien le m√©canisme sous-jacent

**Conditions :**

| Condition | Description |
|-----------|-------------|
| **PRISM** | Agent complet avec m√©ta-SR et d√©tection |
| SR-Blind | Agent SR sans monitoring (Œµ fixe) |
| Q-Learning | Model-free classique (Stable-Baselines3) |

**Crit√®res de succ√®s :**
- PRISM d√©tecte les changements en < 10 √©pisodes
- Latence d'adaptation : PRISM ‚â§ 0.5 √ó SR-Blind
- Asym√©trie R/M observable (confirmation de la signature SR)
- ECE reste < 0.20 m√™me pendant les transitions

### 6.4 Plan d'analyse statistique

**Nombre de runs et puissance.** Chaque condition est ex√©cut√©e 100 fois avec des seeds al√©atoires diff√©rentes (Exp A et C : 100 runs √ó ~500 √©pisodes ; Exp B : 100 runs √ó dur√©e variable). Ce nombre garantit une puissance statistique suffisante pour d√©tecter des diff√©rences d'effet moyen (Cohen's d ‚â• 0.5) avec Œ± = 0.05.

**Tests de comparaison (Exp A, B).** Les distributions de m√©triques (ECE, steps, MI) entre conditions ne sont pas suppos√©es normales. Les comparaisons deux-√†-deux utilisent le test de Mann-Whitney U (unilat√©ral quand la direction est pr√©dite, bilat√©ral sinon). La correction de Holm-Bonferroni est appliqu√©e pour les comparaisons multiples ‚Äî seules les comparaisons pr√©-sp√©cifi√©es dans les crit√®res de succ√®s sont test√©es, pas de fishing.

**Intervalles de confiance.** Les intervalles de confiance √† 95% sur l'ECE et le MI sont calcul√©s par bootstrap non-param√©trique (10 000 re-√©chantillonnages). Les barres d'erreur dans les figures repr√©sentent ces intervalles.

**Tests de calibration (Exp A, C).** En plus de l'ECE, le test de Hosmer-Lemeshow est appliqu√© pour √©valuer formellement la qualit√© de la calibration dans chaque condition. Un p > 0.05 indique une calibration acceptable.

**Corr√©lations (Exp A ‚Äî iso-structuralit√©).** Les corr√©lations œÅ et MI sont report√©es avec des intervalles de confiance bootstrap. La significativit√© est √©valu√©e par un test de permutation (1000 permutations).

**Taille d'effet.** Toutes les comparaisons reportent le Cohen's d (ou r de rang pour Mann-Whitney) en plus du p-value. Un r√©sultat statistiquement significatif mais avec une taille d'effet faible (d < 0.3) sera discut√© comme tel.

---

## 7. Stack technique

### 7.1 D√©pendances

```
Python 3.11+
minigrid >= 2.3, < 3.0  # environnement FourRooms (Farama)
gymnasium >= 0.29, < 1.0 # interface standard RL
numpy >= 1.24, < 2.0     # pinn√© < 2.0 pour compatibilit√© MiniGrid
scipy >= 1.11            # d√©composition spectrale
matplotlib >= 3.7
seaborn >= 0.12          # reliability diagrams, heatmaps
pandas >= 2.0            # logging des r√©sultats
tqdm >= 4.65             # progress bars
pytest >= 7.0            # tests
```

> **Note :** `stable-baselines3` est diff√©r√© √† Phase 3 (baseline Q-learning Exp C).
> Un fallback Q-learning tabulaire est pr√©vu si SB3 pose des probl√®mes de compatibilit√©.

### 7.2 Structure du projet

```
PRISM/
‚îú‚îÄ‚îÄ master.md                          # ‚Üê ce document
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ checkpoints.md                     # Protocoles de validation humaine CP1-CP5
‚îÇ
‚îú‚îÄ‚îÄ prism/                             # Package Python principal
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py                      # [DONE] Hyperparam√®tres centralis√©s (PRISMConfig)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ env/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ state_mapper.py            # [DONE] Mapping position MiniGrid ‚Üí index SR (260 √©tats)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dynamics_wrapper.py        # [DONE] Wrapper perturbations sur MiniGrid
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ exploration_task.py        # [DONE] ExplorationTaskWrapper, place_goals, get_room_cells
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ perturbation_schedule.py   # [STUB Phase 3] Configs de schedules (exp_a/c)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ agent/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sr_layer.py                # [DONE] SR tabulaire (depuis Juliani 2019)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ meta_sr.py                 # [DONE] ‚òÖ Carte U(s), signal C(s), d√©tection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ controller.py              # [DONE] ‚òÖ Œµ adaptatif, V_explore greedy, "je ne sais pas"
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prism_agent.py             # [DONE] ‚òÖ Agent complet assemblant les couches
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ baselines/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_agent.py              # [DONE] BaseSRAgent + RandomAgent (navigation MiniGrid)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sr_blind.py                # [DONE] SREpsilonGreedy + SREpsilonDecay
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sr_count.py                # [DONE] SRCountBonus + SRNormBonus
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sr_bayesian.py             # [DONE] SRPosterior (Thompson sampling)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sr_oracle.py               # [DONE] SROracle (bonus = ||M - M*||)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sb3_baselines.py           # [STUB Phase 3] Q-learning via Stable-Baselines3
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ analysis/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ calibration.py             # [DONE] ‚òÖ ECE, reliability diagrams, MI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ spectral.py                # [DONE] Eigenvectors M (depuis Chelu)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ visualization.py           # [DONE] Heatmaps U/M superpos√©es (animation Phase 3)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.py                 # [DONE] bootstrap_ci, mann_whitney, holm_bonferroni, compare_conditions
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ pedagogy/
‚îÇ       ‚îî‚îÄ‚îÄ toy_grid.py                # [DONE] Grille l√©g√®re pour notebooks (sans MiniGrid)
‚îÇ
‚îú‚îÄ‚îÄ experiments/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ exp_b_exploration.py           # [DONE] Exp B ‚Äî exploration dirig√©e (8 conditions)
‚îÇ   ‚îú‚îÄ‚îÄ exp_a_calibration.py           # [STUB Phase 3] Exp A ‚Äî calibration m√©tacognitive
‚îÇ   ‚îú‚îÄ‚îÄ exp_c_adaptation.py            # [STUB Phase 3] Exp C ‚Äî adaptation au changement
‚îÇ   ‚îî‚îÄ‚îÄ run_all.py                     # [STUB Phase 3] Script batch
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 00_prism_concepts.ipynb        # [DONE] Introduction p√©dagogique aux concepts PRISM
‚îÇ   ‚îú‚îÄ‚îÄ 00a_spectral_deep_dive.ipynb   # [DONE] Analyse spectrale de la SR
‚îÇ   ‚îú‚îÄ‚îÄ 00b_calibration_methods.ipynb  # [DONE] M√©thodes de calibration
‚îÇ   ‚îú‚îÄ‚îÄ 01_sr_validation.ipynb         # [DONE] Validation SR + CP1 go/no-go (9 sections)
‚îÇ   ‚îî‚îÄ‚îÄ 02_experiment_tracking.ipynb   # [TODO] Suivi et analyse Exp B
‚îÇ
‚îú‚îÄ‚îÄ tests/                             # 141 tests, 9 fichiers
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py                    # Fixtures partag√©es (env, mapper)
‚îÇ   ‚îú‚îÄ‚îÄ test_imports.py                # V√©rification imports package
‚îÇ   ‚îú‚îÄ‚îÄ test_env_smoke.py              # Smoke tests MiniGrid
‚îÇ   ‚îú‚îÄ‚îÄ test_state_mapper.py           # Tests StateMapper (260 √©tats, bijection)
‚îÇ   ‚îú‚îÄ‚îÄ test_sr_layer.py               # Tests SR Layer (convergence, update)
‚îÇ   ‚îú‚îÄ‚îÄ test_dynamics_wrapper.py       # Tests DynamicsWrapper (perturbations)
‚îÇ   ‚îú‚îÄ‚îÄ test_meta_sr.py                # Tests MetaSR (uncertainty, confidence, change)
‚îÇ   ‚îú‚îÄ‚îÄ test_calibration.py            # Tests calibration (ECE, MI, reliability)
‚îÇ   ‚îî‚îÄ‚îÄ test_baselines.py              # Tests baselines + metrics + goal placement (44 tests)
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ verify_env.py                  # V√©rification environnement Python
‚îÇ
‚îî‚îÄ‚îÄ results/                           # G√©n√©r√© automatiquement (.gitignored)
    ‚îú‚îÄ‚îÄ exp_a/
    ‚îú‚îÄ‚îÄ exp_b/
    ‚îî‚îÄ‚îÄ exp_c/
```

**L√©gende :**
- ‚òÖ = contribution PRISM (code original)
- [DONE] = impl√©ment√© et test√© (Phases 0-2)
- [STUB Phase 3] = fichier existe avec interface, impl√©mentation en Phase 3

**Compteur :** 141 tests passent, 20 modules Python, 4 notebooks (+1 en cours).

> **Note :** Les baselines (Palier 1 Exp B) et `metrics.py` ont √©t√© impl√©ment√©s en Phase 3.
> Une 9e condition `SR-Count-Matched` est pr√©vue pour le Palier 2 d'Exp B.

---

## 8. Plan d'impl√©mentation

### Phase 1 ‚Äî Assemblage (semaines 1-2) ‚Äî ‚úÖ DONE

Objectif : agent SR fonctionnel dans MiniGrid, z√©ro contribution originale.

- [x] Installer MiniGrid, v√©rifier FourRooms fonctionne
- [x] `state_mapper.py` ‚Äî mapping position MiniGrid ‚Üí index pour matrice SR
- [x] `sr_layer.py` ‚Äî adapter l'impl√©mentation SR tabulaire de Juliani
- [x] `dynamics_wrapper.py` ‚Äî wrapper perturbations (reward shift, door block)
- [x] `spectral.py` ‚Äî adapter le code de visualisation eigenvectors (Chelu)
- [x] Notebook `01_sr_validation.ipynb` ‚Äî sanity check : SR converge, eigenvectors ok
- [x] Tests unitaires : wrapper, SR layer, state mapper

> **Notes d'impl√©mentation :**
> - FourRooms = 19√ó19, **260 √©tats** accessibles (pas ~100 comme anticip√©)
> - `agent_pos` est un tuple `(x, y)`, pas un int ‚Äî n√©cessite `to_grid()` dans StateMapper
> - `max_steps=500` obligatoire pour √©viter la troncation silencieuse
> - Pas de portes dans MiniGrid v2.5 (passages ouverts entre les pi√®ces)

**Milestone :** ‚úÖ L'agent SR navigue vers le goal dans FourRooms. Les heatmaps de M et les eigenvectors sont coh√©rents avec Stachenfeld 2017.
‚Üí **CP1 PASSED** (6 checks automatis√©s dans notebook 01)

### Phase 2 ‚Äî M√©ta-SR et calibration (semaines 3-5) ‚òÖ ‚Äî ‚è≥ PARTIELLEMENT DONE

Objectif : impl√©menter la contribution principale et ex√©cuter l'Exp A.

- [x] `meta_sr.py` ‚Äî buffer d'erreurs, carte U(s), signal C(s), d√©tection
- [x] `controller.py` ‚Äî Œµ adaptatif, V_explore, signal "je ne sais pas"
- [x] `prism_agent.py` ‚Äî assemblage agent complet
- [x] `calibration.py` ‚Äî ECE, reliability diagrams, Metacognitive Index
- [x] `visualization.py` ‚Äî superposition U/M, animations
- [ ] Baselines : `sr_blind.py`, `sr_count.py`, `sr_bayesian.py` ‚Äî stubs seulement
- [ ] **Sweep hyperparam√®tres m√©ta-SR** ‚Äî report√© Phase 3 ‚Üí CP2
- [ ] **Ex√©cuter Exp A** ‚Äî report√© Phase 3 ‚Üí CP3
- [ ] Notebook `02_meta_sr_demo.ipynb` ‚Äî report√© Phase 3

> **Notes d'impl√©mentation :**
> - MetaSR utilise normalisation p99 adaptative (pas min-max na√Øf)
> - L'action exploit du controller est random (pas V_explore voisins comme pr√©vu)
> - `prism_agent.py` int√®gre `config.py` (PRISMConfig) pour centraliser les hyperparam√®tres
> - `hosmer_lemeshow_test()` manquant dans calibration.py ‚Äî √† cr√©er en Phase 3

**Milestone :** Composants logiciels impl√©ment√©s et test√©s (97 tests). Exp A et sweep report√©s Phase 3.

### Phase 3 ‚Äî Exploration et adaptation (semaines 6-8) ‚òÖ ‚Äî √Ä VENIR

Objectif : ex√©cuter les Exp B et C, comparaisons avec baselines.

- [ ] Compl√©ter stubs Phase 2 (baselines, perturbation_schedule, metrics)
- [ ] **Sweep hyperparam√®tres** (depuis Phase 2) ‚Üí CP2
- [ ] **Ex√©cuter Exp A** (depuis Phase 2) ‚Üí CP3
- [ ] Config grand monde pour Exp B (19√ó19, 4+ pi√®ces, 4 goals cach√©s)
- [ ] **Ex√©cuter Exp B** ‚Äî exploration dirig√©e, toutes conditions ‚Üí CP4
- [ ] **Ex√©cuter Exp C** ‚Äî adaptation au changement (perturbations R puis M) ‚Üí CP5
- [ ] `sb3_baselines.py` ‚Äî wrapper Stable-Baselines3 pour Q-learning baseline
- [ ] SR-Oracle baseline (utilise M* comme signal ‚Äî plafond th√©orique Exp B)
- [ ] Analyse crois√©e des 3 exp√©riences
- [ ] Notebook `03_results_analysis.ipynb` ‚Äî figures finales
- [ ] R√©daction du rapport de r√©sultats

**Milestone :** PRISM bat les baselines sur l'exploration. L'asym√©trie R/M confirme la signature SR. La calibration se maintient en dynamique.

### 8.5 Syst√®me de checkpoints

Validation humaine √† chaque √©tape cl√©. Protocoles d√©taill√©s dans `checkpoints.md`.

| CP | Nom | Phase | Crit√®res cl√©s | Statut |
|----|-----|-------|---------------|--------|
| CP1 | Validation SR de base | Fin Phase 1 | ‚ÄñŒîM‚Äñ < 0.1, rang > 50%, ECE < 0.30, MI > 0 | ‚úÖ PASSED |
| CP2 | Hyperparam√®tres m√©ta-SR | Phase 3 (sweep) | ECE < 0.15, stabilit√© inter-runs | ‚è≥ √Ä VENIR |
| CP3 | Calibration m√©tacognitive | Phase 3 (Exp A) | ECE < 0.15, MI > 0.5, PRISM < baselines | ‚è≥ √Ä VENIR |
| CP4 | Exploration dirig√©e | Phase 3 (Exp B) | PRISM ‚àí30% vs Œµ-greedy, < Count-Bonus | ‚è≥ √Ä VENIR |
| CP5 | Adaptation au changement | Phase 3 (Exp C) | D√©tection < 10 √©pisodes, asym√©trie 15-40√ó | ‚è≥ √Ä VENIR |

---

## 9. M√©triques globales

> **Status :** Cibles d√©finies, pas encore test√©es exp√©rimentalement.
> Seul CP1 a valid√© les m√©triques de base (ECE < 0.30, MI > 0).
> Les cibles ci-dessous seront √©valu√©es en Phase 3 (Exp A/B/C).

### Tableau de bord

| Exp | M√©trique | Baseline | Cible PRISM | Teste |
|-----|----------|----------|-------------|-------|
| A | ECE | ‚Äî | < 0.15 | P1 |
| A | Metacognitive Index (MI) | ‚Äî | > 0.5 | P2 |
| A | ECE vs. SR-Global | ECE(SR-Global) | ECE(PRISM) < ECE(SR-Global) | P1 |
| B | Steps pour 4 goals | SR-Œµ-greedy | ‚àí30% | P3 |
| B | Steps PRISM vs. SR-Count-Bonus | SR-Count-Bonus | PRISM < Count-Bonus | P3 (structure) |
| B | Efficiency ratio (PRISM vs. Oracle) | SR-Oracle | > 0.5 (capture >50% du gain th√©orique) | P3 (plafond) |
| C | Latence de d√©tection | SR-Blind | < 10 √©pisodes | P1 |
| C | Latence adaptation PRISM / SR-Blind | SR-Blind | ‚â§ 0.5√ó | P2 |
| C | Asym√©trie latence_M / latence_R | ‚Äî | 15‚Äì40√ó (d√©riv√© analytiquement) | Signature SR |
| C | ECE pendant transitions | ‚Äî | < 0.20 | P1 dynamique |

### M√©triques transversales

- **Metacognitive Index (MI)** = corr(U(s), erreur r√©elle SR). M√©trique reine : l'agent sait-il ce qu'il ne sait pas ?
- **Calibration Maintenance** = ECE mesur√© en fen√™tre glissante. La calibration se d√©grade-t-elle ?
- **Structure Advantage** = gain PRISM vs. SR-Count-Bonus. Isole l'apport de la structure SR.

---

## 10. Extensions futures

### Court terme (si les r√©sultats sont solides)

- **SR multi-√©chelle** : maintenir plusieurs M avec diff√©rents Œ≥, inspir√© de l'axe longitudinal de l'hippocampe. Tester si les cartes U √† diff√©rentes √©chelles capturent diff√©rents types d'incertitude.
- **Replay** : rejeu d'exp√©riences en phases offline pour consolider M, inspir√© du replay hippocampique. Tester l'impact sur la stabilit√© de U.
- **Arbitrage SR/MB** : ajouter un planificateur model-based et utiliser U(s) pour l'arbitrage (Russek et al. 2017). Report√© de la v1 mais pr√™t architecturalement.

### Moyen terme

- **Deep SR** : remplacer la matrice tabulaire par un r√©seau (Chua et al. 2024 comme point de d√©part). La m√©ta-SR peut-elle fonctionner sur des repr√©sentations apprises ?
- **Espaces non-spatiaux** : appliquer PRISM √† un espace s√©mantique (Stoewer et al. 2023) ‚Äî la m√©tacognition SR fonctionne-t-elle au-del√† de la navigation ?

### Recherche

- Comparer la structure spectrale de la SR + m√©ta-SR artificielles avec les donn√©es √©lectrophysiologiques
- Formaliser le lien m√©ta-SR ‚Üî √©nergie libre variationnelle (active inference)
- Explorer si la m√©ta-SR est une approximation de l'incertitude bay√©sienne (Successor Uncertainties) et sous quelles conditions

---

## 11. R√©f√©rences

### Fondations SR

| R√©f | Apport |
|-----|--------|
| Dayan (1993) ‚Äî *Neural Computation* | Formalisme SR original |
| Stachenfeld et al. (2017) ‚Äî *Nature Neuroscience* | Hippocampe comme carte pr√©dictive |
| Gershman (2018) ‚Äî *J. Neuroscience* | Survey SR : logique computationnelle et substrats neuronaux |
| Momennejad et al. (2017) ‚Äî *Nature Human Behaviour* | Preuves comportementales SR chez l'humain |
| Russek et al. (2017) ‚Äî *PLoS Comp Bio* | SR‚ÄìMB hybride, replay, Dyna-SR |
| Barreto et al. (2017) ‚Äî *NeurIPS* | Successor features pour le transfert |

### Espaces cognitifs

| R√©f | Apport |
|-----|--------|
| Bellmund et al. (2018) ‚Äî *Science* | Codes spatiaux pour la pens√©e humaine |
| Theves et al. (2020) ‚Äî *J. Neuroscience* | Hippocampe cartographie l'espace conceptuel |
| Stoewer et al. (2023) ‚Äî *Scientific Reports* | SR sur espaces s√©mantiques (NN artificiels) |
| Ekman et al. (2023) ‚Äî *eLife* | SR dans le cortex visuel |

### M√©tacognition et hippocampe

| R√©f | Apport |
|-----|--------|
| Ambrogioni, L. & √ìlafsd√≥ttir, H. F. (2023) ‚Äî *Trends in Cognitive Sciences*, 27(8), 702-712 | Th√®se fondatrice de PRISM : m√©ta-carte hippocampique comme module de m√©ta-apprentissage |
| Allen et al. (2017) ‚Äî *NeuroImage* | Corr√©lats microstructuraux m√©tacognition‚Äìhippocampe |
| Qiu et al. (2024) ‚Äî *Communications Biology* | Hippocampe + OFC pour espaces abstraits |

### SR et incertitude ‚Äî positionnement direct

| R√©f | Apport | Relation √† PRISM |
|-----|--------|------------------|
| Janz et al. (2019) ‚Äî *NeurIPS* | Successor Uncertainties | Approche bay√©sienne ‚Äî PRISM compare |
| Machado et al. (2020) ‚Äî *AAAI* | Count-based exploration + SR | Norme SR ‚Äî PRISM utilise comme baseline |
| Flennerhag et al. (2020) ‚Äî *DeepMind* | TD uncertainties pour exploration | Signal TD ‚Äî PRISM √©tend en carte structur√©e |
| Chua et al. (2024) ‚Äî *arXiv* | Simple Successor Features | Deep SF depuis pixels ‚Äî extension future |

### M√©tacognition en IA ‚Äî positionnement direct

| R√©f | Apport | Relation √† PRISM |
|-----|--------|------------------|
| Valiente & Pilly (2024/2025) ‚Äî MUSE | Self-assessment + self-regulation | Framework g√©n√©ral ‚Äî PRISM sp√©cifique SR |
| Kawato et al. (2021) ‚Äî *Biol. Cybernetics* | Internal models ‚Üí metacognitive AI | Responsibility signal ‚âà m√©ta-SR |
| Steyvers & Peters (2025) ‚Äî *Perspectives Psych. Science* | M√©tacognition LLMs + calibration | M√©triques ECE ‚Äî PRISM emprunte |

### Global Neuronal Workspace ‚Äî cadre englobant

| R√©f | Apport | Relation √† PRISM |
|-----|--------|------------------|
| Dehaene, Kerszberg & Changeux (1998) ‚Äî *PNAS* | Mod√®le neuronal du GNW | Cadre englobant ‚Äî PRISM = processeur sp√©cialis√© |
| Dehaene & Changeux (2011) ‚Äî *Neuron* | GNW : approches exp√©rimentales et th√©oriques | Ignition, broadcast, seuils |
| Deco, Vidaurre & Kringelbach (2021) ‚Äî *Nature Human Behaviour* | Functional rich club = workspace empirique | Hippocampe dans le core du workspace |
| Whyte & Smith (2020) ‚Äî *Progress in Neurobiology* | Predictive Global Workspace (GNW + active inference) | Pont direct : erreurs de pr√©diction dans le workspace |

### Assets techniques

| Asset | Source | Usage |
|-------|--------|-------|
| MiniGrid | github.com/Farama-Foundation/Minigrid | Environnement |
| SR tabulaire tutorial | Juliani (2019) | Base agent SR |
| Temporal abstraction (spectral) | github.com/veronicachelu/temporal_abstraction | Visualisation eigenvectors |
| SR/MB hybride code | github.com/evanrussek | R√©f√©rence arbitrage |
| Stable-Baselines3 | github.com/DLR-RM/stable-baselines3 | Baselines RL |

---

*Derni√®re mise √† jour : 2026-02-14 ‚Äî Phases 0-2 DONE, Phase 3 √Ä VENIR*
